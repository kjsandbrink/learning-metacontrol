{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood Stats\n",
    "Kai Sandbrink\n",
    "\n",
    "2024-09-30\n",
    "\n",
    "This script aggregates the likelihood tests for both task 1 and task 2. Note that it requires re-running the networks on the human data to determine the likelihood of the trajectories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "### Likelihood estimation: NOTE: This section requires re-running likelihood fits from NNs and will not work out of the box with the included data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from utils import format_axis\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from utils import flatten\n",
    "\n",
    "analysis_folder = os.path.join('panels', 'fig_task1')\n",
    "os.makedirs(analysis_folder, exist_ok=True)\n",
    "\n",
    "effs_to_plot = [1, 0.5, 0]\n",
    "n_steps = 50\n",
    "smoothing_window = 8\n",
    "ylim = (0, 0.3)\n",
    "human_data_file_base = '..' # make sure this points to the repo root folder, or adjust file names in get_clean_data() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from human_utils_project import get_clean_data, sort_train_test\n",
    "\n",
    "day = 'day2'\n",
    "exp_date = '24-01-22-29'\n",
    "\n",
    "day1_test_mask_cutoff = {\n",
    "    \"groupA\": {\"lower\": 10, \"upper\": 90},\n",
    "    \"groupB\": {\"lower\": 8, \"upper\": 72}\n",
    "}\n",
    "\n",
    "group = None\n",
    "\n",
    "df, effs_train, effs_test, test_start = get_clean_data(day = int(day[-1]), exp_date = exp_date, day1_test_mask_cutoff=day1_test_mask_cutoff, group=group, file_base=human_data_file_base)\n",
    "\n",
    "cmap_humans = mpl.colormaps['Greens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: These behavioral files need to be re-generated to determine likelihoods\n",
    "\n",
    "df_file_A_22 = '/home/kai/Documents/Projects/HumanObserveBetEfficacyAnalysis/results/behavior/20240527162302_behavior_diff_effs_24-01-22_day2_with_nets_groupA.pkl'\n",
    "df_file_B_22 = '/home/kai/Documents/Projects/HumanObserveBetEfficacyAnalysis/results/behavior/20240527162823_behavior_diff_effs_24-01-22_day2B_with_nets_groupB.pkl'\n",
    "\n",
    "df_file_A_29 = '/home/kai/Documents/Projects/HumanObserveBetEfficacyAnalysis/results/behavior/20240527164021_behavior_diff_effs_24-01-29_day2_with_nets_groupA.pkl'\n",
    "df_file_B_29 = '/home/kai/Documents/Projects/HumanObserveBetEfficacyAnalysis/results/behavior/20240527164530_behavior_diff_effs_24-01-29_day2B_with_nets_groupB.pkl'\n",
    "\n",
    "df_A = pd.read_pickle(df_file_A_22)\n",
    "df_B = pd.read_pickle(df_file_B_22)\n",
    "\n",
    "df_A_29 = pd.read_pickle(df_file_A_29)\n",
    "df_B_29 = pd.read_pickle(df_file_B_29)\n",
    "\n",
    "df_A = pd.concat([df_A, df_A_29])\n",
    "df_B = pd.concat([df_B, df_B_29])\n",
    "\n",
    "## only keep the rows in df_A that match an index in df (keeping in mind there might be missing keys)\n",
    "df_A = df_A[df_A.index.isin(df.index)]\n",
    "df_B = df_B[df_B.index.isin(df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings_ana import pepe_human_ape_models as ape_models\n",
    "from settings_ana import pepe_human_control_models as control_models\n",
    "from human_utils_project import sort_train_test\n",
    "\n",
    "\n",
    "test_liks_A_ape = []\n",
    "test_liks_A_noape = []\n",
    "test_liks_B_ape = []\n",
    "test_liks_B_noape = []\n",
    "\n",
    "for model in ape_models:\n",
    "    train_liks_A, test_liks_A = sort_train_test(df_A['step_l_%d' %model], df_A['effs'], test_start=5)\n",
    "    test_liks_A_ape.append(test_liks_A)\n",
    "\n",
    "for model in control_models:\n",
    "    train_liks_A, test_liks_A = sort_train_test(df_A['step_l_%d' %model], df_A['effs'], test_start=5)\n",
    "    test_liks_A_noape.append(test_liks_A)\n",
    "\n",
    "for model in ape_models:\n",
    "    train_liks_B, test_liks_B = sort_train_test(df_B['step_l_%d' %model], df_B['effs'], test_start=4)\n",
    "    test_liks_B_ape.append(test_liks_B)\n",
    "\n",
    "for model in control_models:\n",
    "    train_liks_B, test_liks_B = sort_train_test(df_B['step_l_%d' %model], df_B['effs'], test_start=4)\n",
    "    test_liks_B_noape.append(test_liks_B)\n",
    "\n",
    "test_liks_A_ape = np.array(test_liks_A_ape)\n",
    "test_liks_A_noape = np.array(test_liks_A_noape)\n",
    "test_liks_B_ape = np.array(test_liks_B_ape)\n",
    "test_liks_B_noape = np.array(test_liks_B_noape)\n",
    "\n",
    "test_log_liks_A_ape = np.log(test_liks_A_ape).sum(axis=(2,3)).mean(axis=0)\n",
    "test_log_liks_A_noape = np.log(test_liks_A_noape).sum(axis=(2,3)).mean(axis=0)\n",
    "test_log_liks_B_ape = np.log(test_liks_B_ape).sum(axis=(2,3)).mean(axis=0)\n",
    "test_log_liks_B_noape = np.log(test_liks_B_noape).sum(axis=(2,3)).mean(axis=0)\n",
    "\n",
    "test_log_liks_ape = np.concatenate([test_log_liks_A_ape, test_log_liks_B_ape])\n",
    "test_log_liks_noape = np.concatenate([test_log_liks_A_noape, test_log_liks_B_noape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -363.28003,  -607.51385,  -241.255  ,  -576.93225,  -453.8461 ,\n",
       "        -804.7565 ,  -385.7108 ,  -182.80573,  -758.4735 ,  -750.74695,\n",
       "        -201.57501,  -618.94006,  -574.3519 ,  -638.19324,  -554.9235 ,\n",
       "        -716.6028 ,  -976.5804 ,  -235.1971 ,  -353.23267,  -187.86916,\n",
       "        -311.7671 ,  -580.4729 ,  -282.10562,  -208.50418,  -297.87756,\n",
       "        -309.13483,  -216.8081 ,  -254.10506,  -500.02383,  -535.4814 ,\n",
       "        -192.32184,  -260.59918,  -452.52158,  -246.2952 ,  -320.43243,\n",
       "        -296.84903,  -771.46063,  -323.11627,  -234.5413 ,  -494.2418 ,\n",
       "        -314.53595,  -227.60286,  -612.5376 ,  -285.7924 ,  -247.99092,\n",
       "        -587.6279 ,  -914.4038 ,  -330.02673,  -965.02325,  -231.38913,\n",
       "        -774.7299 ,  -264.68396,  -681.96436,  -637.4237 ,  -422.69614,\n",
       "        -448.85825,  -389.39325,  -331.95258,  -363.09833, -1091.1127 ,\n",
       "        -578.2069 ,  -842.6576 ,  -536.635  ,  -713.7173 ,  -416.23984,\n",
       "        -799.1179 ,  -305.7055 ,  -256.49286,  -328.69858,  -737.4984 ,\n",
       "        -252.07124,  -778.1076 ,  -702.0985 ,  -459.4769 ,  -679.00507,\n",
       "        -244.88461,  -249.43655,  -457.98926,  -249.85396,  -516.89087,\n",
       "        -331.92816,  -843.93066,  -872.12366,  -265.4775 ,  -238.64275,\n",
       "        -394.34146,  -811.9674 ,  -615.072  ,  -843.2484 ,  -723.2947 ,\n",
       "        -480.9926 ,  -870.5592 ,  -847.5918 ,  -829.0887 ,  -216.0416 ,\n",
       "        -787.1867 ,  -385.02762,  -352.32278,  -339.47498,  -632.34216,\n",
       "        -235.72299,  -819.83496,  -787.94904,  -267.07138,  -368.38123,\n",
       "        -706.3749 ,  -369.65692,  -210.1001 , -1173.9084 ,  -310.45224,\n",
       "        -478.17212], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_log_liks_ape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model frequencies [0.99553571 0.00446429]\n",
      "Model frequencies variance [3.93305829e-05 3.93305829e-05]\n",
      "Model frequences std [0.00627141 0.00627141]\n",
      "Model SEM [0.00059526 0.00059526]\n",
      "N= 111\n",
      "Exceedance probabilities [1.00000000e+00 2.16065456e-37]\n"
     ]
    }
   ],
   "source": [
    "from groupBMC import GroupBMC\n",
    "\n",
    "L = np.array([test_log_liks_ape, test_log_liks_noape])\n",
    "result = GroupBMC(L).get_result()\n",
    "\n",
    "print(\"Model frequencies\", result.frequency_mean)\n",
    "print(\"Model frequencies variance\", result.frequency_var)\n",
    "print(\"Model frequences std\", np.sqrt(result.frequency_var))\n",
    "print(\"Model SEM\", np.sqrt(result.frequency_var)/ np.sqrt(len(test_log_liks_ape)))\n",
    "print(\"N=\", len(test_log_liks_ape))\n",
    "print(\"Exceedance probabilities\", result.exceedance_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall N 111\n",
      "Test Controllability  1\n",
      "Mean APE 0.64828455\n",
      "StdErr APE 0.032885752642098774\n",
      "N APE 46\n",
      "Mean NOAPE 0.5193321\n",
      "StdErr NOAPE 0.01781263220435191\n",
      "N NOAPE 46\n",
      "TtestResult(statistic=4.382374171570158, pvalue=3.478475123286644e-05, df=45)\n",
      "Test Controllability  0.5\n",
      "Mean APE 0.6098049\n",
      "StdErr APE 0.023917397474663916\n",
      "N APE 65\n",
      "Mean NOAPE 0.4813526\n",
      "StdErr NOAPE 0.013706170910942134\n",
      "N NOAPE 65\n",
      "TtestResult(statistic=5.2869110429825845, pvalue=8.028168688747074e-07, df=64)\n",
      "Test Controllability  0\n",
      "Mean APE 0.5624307\n",
      "StdErr APE 0.0219809138864937\n",
      "N APE 46\n",
      "Mean NOAPE 0.5342141\n",
      "StdErr NOAPE 0.02146576568873027\n",
      "N NOAPE 46\n",
      "TtestResult(statistic=1.0590984795602612, pvalue=0.1476034607207268, df=45)\n",
      "[ True  True False]\n",
      "[6.95695025e-05 2.40845061e-06 1.47603461e-01]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "\n",
    "## MEANS AND SEMS\n",
    "print(\"Overall N\", len(df))\n",
    "\n",
    "p_values = []\n",
    "\n",
    "for level, liks, liks_noape in zip(plotted_levels, test_liks_ape, test_liks_noape):\n",
    "    ## AVERAGE STATS\n",
    "    print(\"Test Controllability \", level)\n",
    "    print(\"Mean APE\", liks.mean())\n",
    "    print(\"StdErr APE\", liks.std()/np.sqrt(liks.shape[0]))\n",
    "    print(\"N APE\", liks.shape[0])\n",
    "    \n",
    "    print(\"Mean NOAPE\", liks_noape.mean())\n",
    "    print(\"StdErr NOAPE\", liks_noape.std()/np.sqrt(liks_noape.shape[0]))\n",
    "    print(\"N NOAPE\", liks_noape.shape[0])\n",
    "\n",
    "    ## paired t-test\n",
    "    ttest = ttest_rel(liks, liks_noape, alternative='greater')\n",
    "    print(ttest)\n",
    "    p_values.append(ttest.pvalue)\n",
    "\n",
    "## MULTIPLE COMPARISONS\n",
    "rejects, p_values_corrected, _, _ = multipletests(p_values, alpha=0.05, method='holm')\n",
    "print(rejects)\n",
    "print(p_values_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Controllability</th>\n",
       "      <th>N</th>\n",
       "      <th>Mean APE</th>\n",
       "      <th>StdErr APE</th>\n",
       "      <th>Mean Standard</th>\n",
       "      <th>StdErr Standard</th>\n",
       "      <th>df</th>\n",
       "      <th>p-value</th>\n",
       "      <th>p-value corrected</th>\n",
       "      <th>reject</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.018</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>65</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.014</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.021</td>\n",
       "      <td>45</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.148</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Controllability   N  Mean APE  StdErr APE  Mean Standard  \\\n",
       "Index                                                             \n",
       "0                  1.0  46     0.648       0.033          0.519   \n",
       "1                  0.5  65     0.610       0.024          0.481   \n",
       "2                  0.0  46     0.562       0.022          0.534   \n",
       "\n",
       "       StdErr Standard  df  p-value  p-value corrected  reject  \n",
       "Index                                                           \n",
       "0                0.018  45    0.000              0.000    True  \n",
       "1                0.014  64    0.000              0.000    True  \n",
       "2                0.021  45    0.148              0.148   False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "for level, liks, liks_noape in zip(plotted_levels, test_liks_ape, test_liks_noape):\n",
    "    # Calculate statistics\n",
    "    mean_ape = liks.mean()\n",
    "    stderr_ape = liks.std()/np.sqrt(liks.shape[0])\n",
    "    n_ape = liks.shape[0]\n",
    "    \n",
    "    mean_noape = liks_noape.mean()\n",
    "    stderr_noape = liks_noape.std()/np.sqrt(liks_noape.shape[0])\n",
    "    n_noape = liks_noape.shape[0]\n",
    "\n",
    "    # Perform t-test\n",
    "    ttest = ttest_rel(liks, liks_noape, alternative='greater')\n",
    "\n",
    "    # Calculate degrees of freedom\n",
    "    df = len(liks) - 1\n",
    "\n",
    "    # Append results to the list\n",
    "    results.append([level, n_ape, mean_ape, stderr_ape, mean_noape, stderr_noape, df, ttest.pvalue, ])\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df_results = pd.DataFrame(results, columns=['Controllability', 'N', 'Mean APE', 'StdErr APE', 'Mean Standard', 'StdErr Standard', 'df', 'p-value',])\n",
    "\n",
    "# Perform multiple comparisons correction\n",
    "rejects, p_values_corrected, _, _ = multipletests(df_results['p-value'], alpha=0.05, method='holm')\n",
    "\n",
    "# Add the corrected p-values and rejection decisions to the DataFrame\n",
    "df_results['p-value corrected'] = p_values_corrected\n",
    "df_results['reject'] = rejects\n",
    "\n",
    "# Set \"Controllability\" to index column\n",
    "#df_results.set_index('Controllability', inplace=True, drop=True)\n",
    "df_results.rename_axis('Index', inplace=True)\n",
    "\n",
    "df_results = df_results.round(3)\n",
    "\n",
    "# Print the DataFrame\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 [0, 0.25, 0.75, 1.0] [0.125, 0.375, 0.5, 0.625, 0.875]\n",
      "0\n",
      "TtestResult(statistic=1.0590984795602612, pvalue=0.1476034607207268, df=45)\n",
      "0.125 [0, 0.25, 0.75, 1.0] [0.125, 0.375, 0.5, 0.625, 0.875]\n",
      "0\n",
      "TtestResult(statistic=4.970849309827105, pvalue=2.6348240429590767e-06, df=64)\n",
      "0.25 [0, 0.25, 0.75, 1.0] [0.125, 0.375, 0.5, 0.625, 0.875]\n",
      "1\n",
      "TtestResult(statistic=5.007846162060969, pvalue=4.480918858467041e-06, df=45)\n",
      "0.375 [0, 0.25, 0.75, 1.0] [0.125, 0.375, 0.5, 0.625, 0.875]\n",
      "1\n",
      "TtestResult(statistic=5.861651237543418, pvalue=8.723881005775804e-08, df=64)\n",
      "0.5 [0, 0.25, 0.75, 1.0] [0.125, 0.375, 0.5, 0.625, 0.875]\n",
      "2\n",
      "TtestResult(statistic=5.2869110429825845, pvalue=8.028168688747074e-07, df=64)\n",
      "0.625 [0, 0.25, 0.75, 1.0] [0.125, 0.375, 0.5, 0.625, 0.875]\n",
      "3\n",
      "TtestResult(statistic=5.037902736140775, pvalue=2.052148936299469e-06, df=64)\n",
      "0.75 [0, 0.25, 0.75, 1.0] [0.125, 0.375, 0.5, 0.625, 0.875]\n",
      "2\n",
      "TtestResult(statistic=5.218004463378611, pvalue=2.2184022254776446e-06, df=45)\n",
      "0.875 [0, 0.25, 0.75, 1.0] [0.125, 0.375, 0.5, 0.625, 0.875]\n",
      "4\n",
      "TtestResult(statistic=3.309770247082907, pvalue=0.000768258778546635, df=64)\n",
      "1.0 [0, 0.25, 0.75, 1.0] [0.125, 0.375, 0.5, 0.625, 0.875]\n",
      "3\n",
      "TtestResult(statistic=4.382374171570158, pvalue=3.478475123286644e-05, df=45)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Controllability</th>\n",
       "      <th>N</th>\n",
       "      <th>Mean APE</th>\n",
       "      <th>StdErr APE</th>\n",
       "      <th>Mean Standard</th>\n",
       "      <th>StdErr Standard</th>\n",
       "      <th>df</th>\n",
       "      <th>t-stat</th>\n",
       "      <th>p-value</th>\n",
       "      <th>p-value corrected</th>\n",
       "      <th>reject</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.021</td>\n",
       "      <td>45</td>\n",
       "      <td>1.059</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.148</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.015</td>\n",
       "      <td>64</td>\n",
       "      <td>4.971</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.019</td>\n",
       "      <td>45</td>\n",
       "      <td>5.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.012</td>\n",
       "      <td>64</td>\n",
       "      <td>5.862</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.014</td>\n",
       "      <td>64</td>\n",
       "      <td>5.287</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.013</td>\n",
       "      <td>64</td>\n",
       "      <td>5.038</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.014</td>\n",
       "      <td>45</td>\n",
       "      <td>5.218</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.012</td>\n",
       "      <td>64</td>\n",
       "      <td>3.310</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.018</td>\n",
       "      <td>45</td>\n",
       "      <td>4.382</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Controllability   N  Mean APE  StdErr APE  Mean Standard  \\\n",
       "Index                                                             \n",
       "0                    0  46     0.562       0.022          0.534   \n",
       "1                    0  65     0.591       0.017          0.493   \n",
       "2                    0  46     0.654       0.021          0.527   \n",
       "3                    0  65     0.613       0.021          0.480   \n",
       "4                    0  65     0.610       0.024          0.481   \n",
       "5                    0  65     0.611       0.027          0.485   \n",
       "6                    0  46     0.660       0.029          0.488   \n",
       "7                    0  65     0.592       0.031          0.488   \n",
       "8                    0  46     0.648       0.033          0.519   \n",
       "\n",
       "       StdErr Standard  df  t-stat  p-value  p-value corrected  reject  \n",
       "Index                                                                   \n",
       "0                0.021  45   1.059    0.148              0.148   False  \n",
       "1                0.015  64   4.971    0.000              0.000    True  \n",
       "2                0.019  45   5.008    0.000              0.000    True  \n",
       "3                0.012  64   5.862    0.000              0.000    True  \n",
       "4                0.014  64   5.287    0.000              0.000    True  \n",
       "5                0.013  64   5.038    0.000              0.000    True  \n",
       "6                0.014  45   5.218    0.000              0.000    True  \n",
       "7                0.012  64   3.310    0.001              0.002    True  \n",
       "8                0.018  45   4.382    0.000              0.000    True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "#for level, liks, liks_noape in zip(effs, test_liks_ape, test_liks_noape):\n",
    "for eff in np.arange(0, 1.01, 0.125):\n",
    "    print(eff, effs_test[0], effs_test[1])\n",
    "    if eff in effs_test[0]:\n",
    "        print(effs_test[0].index(eff))\n",
    "    else:\n",
    "        print(effs_test[1].index(eff))\n",
    "    liks = test_liks_A_ape[:, :, effs_test[0].index(eff)] if eff in effs_test[0] else test_liks_B_ape[:, :, effs_test[1].index(eff)]\n",
    "    liks = liks.mean(axis=(0,-1))\n",
    "    liks_noape = test_liks_A_noape[:, :, effs_test[0].index(eff)] if eff in effs_test[0] else test_liks_B_noape[:, :, effs_test[1].index(eff)]\n",
    "    liks_noape = liks_noape.mean(axis=(0,-1))\n",
    "\n",
    "    # Calculate statistics\n",
    "    mean_ape = liks.mean()\n",
    "    stderr_ape = liks.std()/np.sqrt(liks.shape[0])\n",
    "    n_ape = liks.shape[0]\n",
    "    \n",
    "    mean_noape = liks_noape.mean()\n",
    "    stderr_noape = liks_noape.std()/np.sqrt(liks_noape.shape[0])\n",
    "    n_noape = liks_noape.shape[0]\n",
    "\n",
    "    # Perform t-test\n",
    "    ttest = ttest_rel(liks, liks_noape, alternative='greater')\n",
    "    print(ttest)\n",
    "\n",
    "    # Calculate degrees of freedom\n",
    "    df = len(liks) - 1\n",
    "\n",
    "    # Append results to the list\n",
    "    results.append([level, n_ape, mean_ape, stderr_ape, mean_noape, stderr_noape, df, ttest[0], ttest.pvalue, ])\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df_results = pd.DataFrame(results, columns=['Controllability', 'N', 'Mean APE', 'StdErr APE', 'Mean Standard', 'StdErr Standard', 'df', 't-stat', 'p-value',])\n",
    "\n",
    "# Perform multiple comparisons correction\n",
    "rejects, p_values_corrected, _, _ = multipletests(df_results['p-value'], alpha=0.05, method='holm')\n",
    "\n",
    "# Add the corrected p-values and rejection decisions to the DataFrame\n",
    "df_results['p-value corrected'] = p_values_corrected\n",
    "df_results['reject'] = rejects\n",
    "\n",
    "# Set \"Controllability\" to index column\n",
    "#df_results.set_index('Controllability', inplace=True, drop=True)\n",
    "df_results.rename_axis('Index', inplace=True)\n",
    "\n",
    "df_results = df_results.round(3)\n",
    "\n",
    "# Print the DataFrame\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 65, 5, 50)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test_liks_A_ape.shape\n",
    "test_liks_B_ape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[0.21268047276849933, 0.09889201639633535, 0....\n",
       "1    [[0.21268047276849933, 0.9686015378958075, 0.6...\n",
       "2    [[0.21268047276849933, 0.16316568433457407, 0....\n",
       "3    [[0.21268047276849933, 0.9209015922552268, 0.1...\n",
       "4    [[0.21268047276849933, 0.9209015922552268, 0.9...\n",
       "5    [[0.21268047276849933, 0.9686015378958075, 0.6...\n",
       "6    [[0.21268047276849933, 0.09889201639633535, 0....\n",
       "7    [[0.21268047276849933, 0.9686015378958075, 0.0...\n",
       "8    [[0.21268047276849933, 0.16316568433457407, 0....\n",
       "Name: p-value, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results['p-value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "### NOTE: This section requires re-running likelihood fits from NNs and will not work out of the box with the included data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from utils import format_axis\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from utils import flatten\n",
    "\n",
    "analysis_folder = os.path.join('panels', 'fig_task2')\n",
    "os.makedirs(analysis_folder, exist_ok=True)\n",
    "\n",
    "effs_to_plot = [1, 0.5, 0]\n",
    "n_steps = 50\n",
    "smoothing_window = 4\n",
    "ylim = (-0.01,0.45)\n",
    "\n",
    "exp_date = '24-01-22-29'\n",
    "human_data_file_base = '..' # make sure the cwd points to the root repo folder, else adjust here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from human_utils_project import get_clean_data, sort_train_test\n",
    "\n",
    "day = 'day3'\n",
    "exp_date = '24-01-22-29'\n",
    "\n",
    "day1_test_mask_cutoff = {\n",
    "    \"groupA\": {\"lower\": 10, \"upper\": 90},\n",
    "    \"groupB\": {\"lower\": 8, \"upper\": 72}\n",
    "}\n",
    "\n",
    "group = None\n",
    "\n",
    "df, effs_train, effs_test, test_start = get_clean_data(day = int(day[-1]), exp_date = exp_date, day1_test_mask_cutoff=day1_test_mask_cutoff, group=group, file_base=human_data_file_base)\n",
    "\n",
    "cmap_humans = mpl.colormaps['Greens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: Likelihoods need to be recomputed for the public datasets\n",
    "\n",
    "df_file_A_22 = '/home/kai/Documents/Projects/HumanObserveBetEfficacyAnalysis/results/behavior/20240527162546_behavior_diff_effs_24-01-22_day3_with_nets_groupA.pkl'\n",
    "df_file_B_22 = '/home/kai/Documents/Projects/HumanObserveBetEfficacyAnalysis/results/behavior/20240527163117_behavior_diff_effs_24-01-22_day3B_with_nets_groupB.pkl'\n",
    "\n",
    "df_file_A_29 = '/home/kai/Documents/Projects/HumanObserveBetEfficacyAnalysis/results/behavior/20240527164255_behavior_diff_effs_24-01-29_day3_with_nets_groupA.pkl'\n",
    "df_file_B_29 = '/home/kai/Documents/Projects/HumanObserveBetEfficacyAnalysis/results/behavior/20240527164833_behavior_diff_effs_24-01-29_day3B_with_nets_groupB.pkl'\n",
    "\n",
    "df_A = pd.read_pickle(df_file_A_22)\n",
    "df_B = pd.read_pickle(df_file_B_22) \n",
    "\n",
    "df_A_29 = pd.read_pickle(df_file_A_29)\n",
    "df_B_29 = pd.read_pickle(df_file_B_29)\n",
    "\n",
    "df_A = pd.concat([df_A, df_A_29])\n",
    "df_B = pd.concat([df_B, df_B_29])\n",
    "\n",
    "## only keep the rows in df_A that match an index in df (keeping in mind there might be missing keys)\n",
    "df_A = df_A[df_A.index.isin(df.index)]\n",
    "df_B = df_B[df_B.index.isin(df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings_anal import levc_human_ape_models as ape_models\n",
    "from settings_anal import levc_human_control_models as control_models\n",
    "from human_utils_project import sort_train_test\n",
    "\n",
    "\n",
    "test_liks_A_ape = []\n",
    "test_liks_A_noape = []\n",
    "test_liks_B_ape = []\n",
    "test_liks_B_noape = []\n",
    "\n",
    "for model in ape_models:\n",
    "    train_liks_A, test_liks_A = sort_train_test(df_A['step_l_%d' %model], df_A['effs'], test_start=5)\n",
    "    test_liks_A_ape.append(test_liks_A)\n",
    "\n",
    "for model in control_models:\n",
    "    train_liks_A, test_liks_A = sort_train_test(df_A['step_l_%d' %model], df_A['effs'], test_start=5)\n",
    "    test_liks_A_noape.append(test_liks_A)\n",
    "\n",
    "for model in ape_models:\n",
    "    train_liks_B, test_liks_B = sort_train_test(df_B['step_l_%d' %model], df_B['effs'], test_start=4)\n",
    "    test_liks_B_ape.append(test_liks_B)\n",
    "\n",
    "for model in control_models:\n",
    "    train_liks_B, test_liks_B = sort_train_test(df_B['step_l_%d' %model], df_B['effs'], test_start=4)\n",
    "    test_liks_B_noape.append(test_liks_B)\n",
    "\n",
    "test_liks_A_ape = np.array(test_liks_A_ape)\n",
    "test_liks_A_noape = np.array(test_liks_A_noape)\n",
    "test_liks_B_ape = np.array(test_liks_B_ape)\n",
    "test_liks_B_noape = np.array(test_liks_B_noape)\n",
    "\n",
    "test_log_liks_A_ape = np.log(test_liks_A_ape).sum(axis=(2,3)).mean(axis=0)\n",
    "test_log_liks_A_noape = np.log(test_liks_A_noape).sum(axis=(2,3)).mean(axis=0)\n",
    "test_log_liks_B_ape = np.log(test_liks_B_ape).sum(axis=(2,3)).mean(axis=0)\n",
    "test_log_liks_B_noape = np.log(test_liks_B_noape).sum(axis=(2,3)).mean(axis=0)\n",
    "\n",
    "test_log_liks_ape = np.concatenate([test_log_liks_A_ape, test_log_liks_B_ape])\n",
    "test_log_liks_noape = np.concatenate([test_log_liks_A_noape, test_log_liks_B_noape])\n",
    "\n",
    "# test_liks_ape = [test_liks_A_ape[:,:,-1].mean(axis=(0,-1)), test_liks_B_ape[:,:,2].mean(axis=(0,-1)), test_liks_A_ape[:,:,0].mean(axis=(0,-1))]\n",
    "# test_liks_noape = [test_liks_A_noape[:,:,-1].mean(axis=(0,-1)), test_liks_B_noape[:,:,2].mean(axis=(0,-1)), test_liks_A_noape[:,:,0].mean(axis=(0,-1))]\n",
    "# plotted_levels = [1, 0.5, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -197.83769,  -284.6319 ,  -233.1812 ,  -220.8844 ,  -221.2203 ,\n",
       "        -733.79504,  -398.6971 ,  -202.44339,  -806.04236,  -345.07184,\n",
       "        -265.52676,  -203.70082,  -294.41754, -1049.3402 ,  -498.6441 ,\n",
       "        -972.40173,  -460.56308,  -432.02695,  -192.05376,  -262.62842,\n",
       "        -236.20499,  -422.20792,  -238.02426,  -196.30826,  -304.10147,\n",
       "        -314.53888,  -237.30725,  -262.80548,  -312.25357,  -582.5339 ,\n",
       "        -270.95837,  -709.74207,  -248.02237,  -254.21634,  -317.00272,\n",
       "        -235.64572,  -870.8379 ,  -445.5019 ,  -567.8578 ,  -620.9753 ,\n",
       "        -423.09247,  -348.28445,  -378.2017 ,  -357.99625,  -207.94804,\n",
       "        -589.31476, -1000.8417 ,  -239.45393, -1029.8069 ,  -271.90118,\n",
       "        -414.3558 ,  -390.80472,  -533.6897 ,  -319.40985,  -360.9077 ,\n",
       "        -657.719  ,  -338.20792,  -378.60736,  -403.79926, -1011.6603 ,\n",
       "        -366.1418 ,  -652.0687 ,  -525.0365 , -1397.2034 ,  -316.46332,\n",
       "        -932.3524 ,  -380.83554,  -250.42998,  -399.5611 ,  -509.6587 ,\n",
       "        -190.92691, -1149.6594 ,  -958.75195,  -300.97662, -1231.0026 ,\n",
       "        -407.90262,  -222.23479,  -365.1018 ,  -389.01938,  -299.96985,\n",
       "        -177.86493, -1119.5696 ,  -961.7666 ,  -279.2179 ,  -290.43042,\n",
       "        -306.57318,  -659.8405 ,  -389.35806, -1050.2969 ,  -292.38898,\n",
       "        -446.37726,  -979.5917 , -1148.5715 , -1137.8881 ,  -261.07928,\n",
       "        -870.2572 ,  -315.54404,  -415.3549 ,  -544.8653 ,  -813.277  ,\n",
       "        -581.50476,  -779.0399 ,  -640.7628 ,  -482.04413,  -429.0477 ,\n",
       "        -758.03894,  -460.067  ,  -289.8032 ,  -760.9371 ,  -237.85551,\n",
       "        -334.87885], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_log_liks_ape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model frequencies [0.99553571 0.00446429]\n",
      "Model frequencies variance [3.93305829e-05 3.93305829e-05]\n",
      "Model frequences std [0.00627141 0.00627141]\n",
      "Model SEM [0.00059526 0.00059526]\n",
      "N= 111\n",
      "Exceedance probabilities [1.00000000e+00 2.16065456e-37]\n"
     ]
    }
   ],
   "source": [
    "from groupBMC import GroupBMC\n",
    "\n",
    "L = np.array([test_log_liks_ape, test_log_liks_noape])\n",
    "result = GroupBMC(L).get_result()\n",
    "\n",
    "print(\"Model frequencies\", result.frequency_mean)\n",
    "print(\"Model frequencies variance\", result.frequency_var)\n",
    "print(\"Model frequences std\", np.sqrt(result.frequency_var))\n",
    "print(\"Model SEM\", np.sqrt(result.frequency_var)/ np.sqrt(len(test_log_liks_ape)))\n",
    "print(\"N=\", len(test_log_liks_ape))\n",
    "print(\"Exceedance probabilities\", result.exceedance_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall N 111\n",
      "Test Controllability  1\n",
      "Mean APE 0.6610438\n",
      "StdErr APE 0.029985651435308458\n",
      "N APE 46\n",
      "Mean NOAPE 0.59373236\n",
      "StdErr NOAPE 0.0244556605887658\n",
      "N NOAPE 46\n",
      "TtestResult(statistic=5.935950362367477, pvalue=1.943115681870144e-07, df=45)\n",
      "Test Controllability  0.5\n",
      "Mean APE 0.5539967\n",
      "StdErr APE 0.03104156052417598\n",
      "N APE 65\n",
      "Mean NOAPE 0.51043034\n",
      "StdErr NOAPE 0.024744829064261845\n",
      "N NOAPE 65\n",
      "TtestResult(statistic=4.44496127641961, pvalue=1.7844602690548575e-05, df=64)\n",
      "Test Controllability  0\n",
      "Mean APE 0.5938757\n",
      "StdErr APE 0.0280230078106912\n",
      "N APE 46\n",
      "Mean NOAPE 0.5353945\n",
      "StdErr NOAPE 0.02440152731722509\n",
      "N NOAPE 46\n",
      "TtestResult(statistic=5.387383614311002, pvalue=1.2539182859163282e-06, df=45)\n",
      "[ True  True  True]\n",
      "[5.82934705e-07 1.78446027e-05 2.50783657e-06]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "\n",
    "## MEANS AND SEMS\n",
    "print(\"Overall N\", len(df))\n",
    "\n",
    "p_values = []\n",
    "\n",
    "for level, liks, liks_noape in zip(plotted_levels, test_liks_ape, test_liks_noape):\n",
    "    ## AVERAGE STATS\n",
    "    print(\"Test Controllability \", level)\n",
    "    print(\"Mean APE\", liks.mean())\n",
    "    print(\"StdErr APE\", liks.std()/np.sqrt(liks.shape[0]))\n",
    "    print(\"N APE\", liks.shape[0])\n",
    "    \n",
    "    print(\"Mean NOAPE\", liks_noape.mean())\n",
    "    print(\"StdErr NOAPE\", liks_noape.std()/np.sqrt(liks_noape.shape[0]))\n",
    "    print(\"N NOAPE\", liks_noape.shape[0])\n",
    "\n",
    "    ## paired t-test\n",
    "    ttest = ttest_rel(liks, liks_noape, alternative='greater')\n",
    "    print(ttest)\n",
    "    p_values.append(ttest.pvalue)\n",
    "\n",
    "## MULTIPLE COMPARISONS\n",
    "rejects, p_values_corrected, _, _ = multipletests(p_values, alpha=0.05, method='holm')\n",
    "print(rejects)\n",
    "print(p_values_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Controllability</th>\n",
       "      <th>N</th>\n",
       "      <th>Mean APE</th>\n",
       "      <th>StdErr APE</th>\n",
       "      <th>Mean Standard</th>\n",
       "      <th>StdErr Standard</th>\n",
       "      <th>df</th>\n",
       "      <th>p-value</th>\n",
       "      <th>p-value corrected</th>\n",
       "      <th>reject</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.024</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>65</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.025</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.024</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Controllability   N  Mean APE  StdErr APE  Mean Standard  \\\n",
       "Index                                                             \n",
       "0                  1.0  46     0.661       0.030          0.594   \n",
       "1                  0.5  65     0.554       0.031          0.510   \n",
       "2                  0.0  46     0.594       0.028          0.535   \n",
       "\n",
       "       StdErr Standard  df p-value p-value corrected  reject  \n",
       "Index                                                         \n",
       "0                0.024  45   0.000             0.000    True  \n",
       "1                0.025  64   0.000             0.000    True  \n",
       "2                0.024  45   0.000             0.000    True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "for level, liks, liks_noape in zip(plotted_levels, test_liks_ape, test_liks_noape):\n",
    "    # Calculate statistics\n",
    "    mean_ape = liks.mean()\n",
    "    stderr_ape = liks.std()/np.sqrt(liks.shape[0])\n",
    "    n_ape = liks.shape[0]\n",
    "    \n",
    "    mean_noape = liks_noape.mean()\n",
    "    stderr_noape = liks_noape.std()/np.sqrt(liks_noape.shape[0])\n",
    "    n_noape = liks_noape.shape[0]\n",
    "\n",
    "    # Perform t-test\n",
    "    ttest = ttest_rel(liks, liks_noape, alternative='greater')\n",
    "\n",
    "    # Calculate degrees of freedom\n",
    "    df = len(liks) - 1\n",
    "\n",
    "    # Append results to the list\n",
    "    results.append([level, n_ape, mean_ape, stderr_ape, mean_noape, stderr_noape, df, ttest.pvalue, ])\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df_results = pd.DataFrame(results, columns=['Controllability', 'N', 'Mean APE', 'StdErr APE', 'Mean Standard', 'StdErr Standard', 'df', 'p-value',])\n",
    "\n",
    "# Perform multiple comparisons correction\n",
    "rejects, p_values_corrected, _, _ = multipletests(df_results['p-value'], alpha=0.05, method='holm')\n",
    "\n",
    "# Add the corrected p-values and rejection decisions to the DataFrame\n",
    "df_results['p-value corrected'] = p_values_corrected\n",
    "df_results['reject'] = rejects\n",
    "\n",
    "# Set \"Controllability\" to index column\n",
    "#df_results.set_index('Controllability', inplace=True, drop=True)\n",
    "df_results.rename_axis('Index', inplace=True)\n",
    "\n",
    "df_results = df_results.round(3)\n",
    "\n",
    "df_results['p-value'] = df_results['p-value'].map('{:.3f}'.format)\n",
    "df_results['p-value corrected'] = df_results['p-value corrected'].map('{:.3f}'.format)\n",
    "\n",
    "# Print the DataFrame\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 [0, 0.25, 0.75, 1.0] [0.125, 0.375, 0.5, 0.625, 0.875]\n",
      "0\n",
      "TtestResult(statistic=5.387383614311002, pvalue=1.2539182859163282e-06, df=45)\n",
      "0.125 [0, 0.25, 0.75, 1.0] [0.125, 0.375, 0.5, 0.625, 0.875]\n",
      "0\n",
      "TtestResult(statistic=4.2435791080913665, pvalue=3.620496584365552e-05, df=64)\n",
      "0.25 [0, 0.25, 0.75, 1.0] [0.125, 0.375, 0.5, 0.625, 0.875]\n",
      "1\n",
      "TtestResult(statistic=5.657191703368873, pvalue=5.024909930712447e-07, df=45)\n",
      "0.375 [0, 0.25, 0.75, 1.0] [0.125, 0.375, 0.5, 0.625, 0.875]\n",
      "1\n",
      "TtestResult(statistic=4.300768573277472, pvalue=2.9660742886021207e-05, df=64)\n",
      "0.5 [0, 0.25, 0.75, 1.0] [0.125, 0.375, 0.5, 0.625, 0.875]\n",
      "2\n",
      "TtestResult(statistic=4.44496127641961, pvalue=1.7844602690548575e-05, df=64)\n",
      "0.625 [0, 0.25, 0.75, 1.0] [0.125, 0.375, 0.5, 0.625, 0.875]\n",
      "3\n",
      "TtestResult(statistic=5.22771002563792, pvalue=1.0049307742633908e-06, df=64)\n",
      "0.75 [0, 0.25, 0.75, 1.0] [0.125, 0.375, 0.5, 0.625, 0.875]\n",
      "2\n",
      "TtestResult(statistic=5.500449162942592, pvalue=8.55403202875173e-07, df=45)\n",
      "0.875 [0, 0.25, 0.75, 1.0] [0.125, 0.375, 0.5, 0.625, 0.875]\n",
      "4\n",
      "TtestResult(statistic=3.398773920150186, pvalue=0.000584642588631607, df=64)\n",
      "1.0 [0, 0.25, 0.75, 1.0] [0.125, 0.375, 0.5, 0.625, 0.875]\n",
      "3\n",
      "TtestResult(statistic=5.935950362367477, pvalue=1.943115681870144e-07, df=45)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Controllability</th>\n",
       "      <th>N</th>\n",
       "      <th>Mean APE</th>\n",
       "      <th>StdErr APE</th>\n",
       "      <th>Mean Standard</th>\n",
       "      <th>StdErr Standard</th>\n",
       "      <th>df</th>\n",
       "      <th>p-value</th>\n",
       "      <th>p-value corrected</th>\n",
       "      <th>reject</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.024</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.024</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.027</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.025</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.025</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.026</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.024</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.024</td>\n",
       "      <td>64</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.024</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Controllability   N  Mean APE  StdErr APE  Mean Standard  \\\n",
       "Index                                                             \n",
       "0                    0  46     0.594       0.028          0.535   \n",
       "1                    0  65     0.537       0.029          0.501   \n",
       "2                    0  46     0.606       0.031          0.546   \n",
       "3                    0  65     0.565       0.030          0.525   \n",
       "4                    0  65     0.554       0.031          0.510   \n",
       "5                    0  65     0.573       0.032          0.523   \n",
       "6                    0  46     0.664       0.029          0.607   \n",
       "7                    0  65     0.576       0.032          0.535   \n",
       "8                    0  46     0.661       0.030          0.594   \n",
       "\n",
       "       StdErr Standard  df  p-value  p-value corrected  reject  \n",
       "Index                                                           \n",
       "0                0.024  45    0.000              0.000    True  \n",
       "1                0.024  64    0.000              0.000    True  \n",
       "2                0.027  45    0.000              0.000    True  \n",
       "3                0.025  64    0.000              0.000    True  \n",
       "4                0.025  64    0.000              0.000    True  \n",
       "5                0.026  64    0.000              0.000    True  \n",
       "6                0.024  45    0.000              0.000    True  \n",
       "7                0.024  64    0.001              0.001    True  \n",
       "8                0.024  45    0.000              0.000    True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "#for level, liks, liks_noape in zip(effs, test_liks_ape, test_liks_noape):\n",
    "for eff in np.arange(0, 1.01, 0.125):\n",
    "    print(eff, effs_test[0], effs_test[1])\n",
    "    if eff in effs_test[0]:\n",
    "        print(effs_test[0].index(eff))\n",
    "    else:\n",
    "        print(effs_test[1].index(eff))\n",
    "    liks = test_liks_A_ape[:, :, effs_test[0].index(eff)] if eff in effs_test[0] else test_liks_B_ape[:, :, effs_test[1].index(eff)]\n",
    "    liks = liks.mean(axis=(0,-1))\n",
    "    liks_noape = test_liks_A_noape[:, :, effs_test[0].index(eff)] if eff in effs_test[0] else test_liks_B_noape[:, :, effs_test[1].index(eff)]\n",
    "    liks_noape = liks_noape.mean(axis=(0,-1))\n",
    "\n",
    "    # Calculate statistics\n",
    "    mean_ape = liks.mean()\n",
    "    stderr_ape = liks.std()/np.sqrt(liks.shape[0])\n",
    "    n_ape = liks.shape[0]\n",
    "    \n",
    "    mean_noape = liks_noape.mean()\n",
    "    stderr_noape = liks_noape.std()/np.sqrt(liks_noape.shape[0])\n",
    "    n_noape = liks_noape.shape[0]\n",
    "\n",
    "    # Perform t-test\n",
    "    ttest = ttest_rel(liks, liks_noape, alternative='greater')\n",
    "    print(ttest)\n",
    "\n",
    "    # Calculate degrees of freedom\n",
    "    df = len(liks) - 1\n",
    "\n",
    "    # Append results to the list\n",
    "    results.append([level, n_ape, mean_ape, stderr_ape, mean_noape, stderr_noape, df, ttest.pvalue, ])\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df_results = pd.DataFrame(results, columns=['Controllability', 'N', 'Mean APE', 'StdErr APE', 'Mean Standard', 'StdErr Standard', 'df', 'p-value',])\n",
    "\n",
    "# Perform multiple comparisons correction\n",
    "rejects, p_values_corrected, _, _ = multipletests(df_results['p-value'], alpha=0.05, method='holm')\n",
    "\n",
    "# Add the corrected p-values and rejection decisions to the DataFrame\n",
    "df_results['p-value corrected'] = p_values_corrected\n",
    "df_results['reject'] = rejects\n",
    "\n",
    "# Set \"Controllability\" to index column\n",
    "#df_results.set_index('Controllability', inplace=True, drop=True)\n",
    "df_results.rename_axis('Index', inplace=True)\n",
    "\n",
    "df_results = df_results.round(3)\n",
    "\n",
    "# Print the DataFrame\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
